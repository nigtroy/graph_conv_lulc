{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3628b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import ee\n",
    "import pandas as pd\n",
    "import geemap\n",
    "\n",
    "# Trigger ee authentication \n",
    "ee.Authenticate()\n",
    " \n",
    "# # Initializeee library\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58a2d5-bd83-4bf0-bb95-b40d60baa674",
   "metadata": {},
   "source": [
    "- classification accuracy metrics for general and individual classes\n",
    "- year land cover maps\n",
    "- statistics for the land size of classes covered\n",
    "- methodoly explanation of the graph convolutional network\n",
    "- models \n",
    "- regerate data visaulisation and statistical metrics for the training satellite data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf011b7-913a-4bf3-9b08-54e08c558448",
   "metadata": {},
   "source": [
    "    project/\n",
    "      ├── data/\n",
    "      │   ├── landsat_accra.tif\n",
    "      │   ├── osm_graph_accra.gpickle\n",
    "      ├── scripts/\n",
    "      │   ├── preprocess_grid.py\n",
    "      │   ├── preprocess_osm.py\n",
    "      │   ├── model.py\n",
    "      │   ├── train.py\n",
    "      ├── results/\n",
    "      ├── README.md\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ec6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from rasterio.plot import show\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import networkx as nx\n",
    "from shapely.geometry import box\n",
    "from rasterio.warp import transform_bounds\n",
    "from pyproj import CRS\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterstats import zonal_stats\n",
    "import osmnx as ox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting ROI (Region of Interest)\n",
    "# imageROI = ee.Geometry.Rectangle(-1.5493322237426321,6.4533743404043244,-1.4198995455199759,6.561506439869568) #Polygon surrounding the Techiman area\n",
    "imageROI = ee.Geometry.Rectangle(-1.5880583877622567,6.157655377979639,-1.7260741348325692,6.253563761708023)\n",
    "location = imageROI.centroid().coordinates().getInfo()[::-1] #Getting the centroid location inside the polygon for centering in Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroid for map centering (optional)\n",
    "location = imageROI.centroid().coordinates().getInfo()[::-1]\n",
    "\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Masks clouds in a Sentinel-2 image using the QA band.\n",
    "\n",
    "      Args:\n",
    "          image (ee.Image): A Sentinel-2 image.\n",
    "\n",
    "      Returns:\n",
    "      ee.Image: A cloud-masked Sentinel-2 image.\n",
    "    \"\"\"\n",
    "    qa = image.select('QA60')\n",
    "\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = (\n",
    "      qa.bitwiseAnd(cloud_bit_mask)\n",
    "      .eq(0)\n",
    "      .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    ")\n",
    "\n",
    "    return image.updateMask(mask).divide(10000)\n",
    "\n",
    "\n",
    "# Apply cloud mask to each image\n",
    "sentinel = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \n",
    "    .filterBounds(imageROI) \n",
    "    .filterDate('2021-01-01', '2021-03-31') \n",
    "    # Pre-filter to get less cloudy granules.\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \n",
    "    .map(mask_s2_clouds) \n",
    "    .median()\n",
    ")\n",
    "\n",
    "\n",
    "# Select bands (e.g., Blue, Green, Red, NIR)\n",
    "bands = ['B2', 'B3', 'B4', 'B8']\n",
    "image = sentinel.select(bands)\n",
    "\n",
    "# Clip to the rectangle region (NOT district)\n",
    "clipped = image.clip(imageROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f82fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0aeceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the geemap Map\n",
    "Map = geemap.Map(center=location, zoom=12)\n",
    "Map.addLayer(clipped, {\n",
    "    'bands': ['B4', 'B3', 'B2'],  # RGB visualization\n",
    "    'min': 0,\n",
    "    'max': 0.3\n",
    "}, 'Clipped Sentinel-2 Image (Kumasi)')\n",
    "\n",
    "# Optionally add the ROI outline\n",
    "Map.addLayer(imageROI, {}, 'ROI Boundary')\n",
    "\n",
    "# Display the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74118928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bda249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Export\n",
    "geemap.ee_export_image(\n",
    "    clipped, filename='obuasi.tif', scale=10, region=imageROI, file_per_band=False\n",
    ")\n",
    "\n",
    "print(\"Image prepared and clipped to Techiman region!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacf13e",
   "metadata": {},
   "source": [
    "####  Downloading Sentinel data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbed3b3",
   "metadata": {},
   "source": [
    "### Get  land cover labels using Esri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESRI Global Land Cover dataset\n",
    "# lc = ee.ImageCollection(\"projects/sat-io/open-datasets/landcover/ESRI_Global-LULC_10m_TS\") \\\n",
    "#     .mosaic() \\\n",
    "#     .clip(imageROI)\n",
    "\n",
    "# # Select the label band (usually only one band)\n",
    "# label = lc.select('b1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757cff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export label image\n",
    "# geemap.ee_export_image(\n",
    "#     label, \n",
    "#     filename='./esri_landcover_obuasi_label.tif',\n",
    "#     scale=10, \n",
    "#     region=imageROI,\n",
    "#     file_per_band=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa89cf-41e4-4439-925c-577c14ba3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "# Define a dictionary which will be used to make legend and visualize image on map\n",
    "dict_legend = {\n",
    "  \"names\": [\n",
    "    \"Water\",\n",
    "    \"Trees\",\n",
    "    \"Flooded Vegetation\",\n",
    "    \"Crops\", \n",
    "    \"Built Area\",\n",
    "    \"Bare Ground\",\n",
    "    # \"Snow/Ice\",\n",
    "    # \"Clouds\",  \n",
    "    # \"Rangeland\"\n",
    "  ],\n",
    "  \n",
    "  \"colors\": [\n",
    "    \"#1A5BAB\",\n",
    "    \"#358221\",\n",
    "    \"#87D19E\",\n",
    "    \"#FFDB5C\",\n",
    "    \"#ED022A\",\n",
    "    \"#EDE9E4\",\n",
    "    # \"#F2FAFF\",\n",
    "    # \"#C8C8C8\",\n",
    "    # \"#C6AD8D\"  \n",
    "  ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4804ae-3c55-4526-abc0-73dce455c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESRI Global LULC 10m Time Series\n",
    "esri_lulc10 = ee.ImageCollection(\"projects/sat-io/open-datasets/landcover/ESRI_Global-LULC_10m_TS\")\n",
    "\n",
    "# Remap function: maps ESRI class values to sequential class IDs (1–9)\n",
    "def remapper(image):\n",
    "    return image.remap([1, 2, 4, 5, 7, 8, 9, 10, 11],\n",
    "                       [1, 2, 3, 4, 5, 6, 7, 8, 9]).rename('landcover')\n",
    "\n",
    "# Filter for 2017 and mosaic\n",
    "lulc_2017 = esri_lulc10.filterDate('2018-01-01', '2018-12-31').mosaic().clip(imageROI)\n",
    "lulc_2017_remapped = remapper(lulc_2017)\n",
    "\n",
    "# Print to confirm\n",
    "lulc_2017_remapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4662d18-66e3-44c7-b5b8-cb9ac19efdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export label image\n",
    "geemap.ee_export_image(\n",
    "    lulc_2017_remapped, \n",
    "    filename='./esri_landcover_obuasi_label.tif',\n",
    "    scale=10, \n",
    "    region=imageROI,\n",
    "    file_per_band=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5af22-024a-43cf-972e-7619d4841a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization dictionary\n",
    "esri_viz = {\n",
    "    'min': 1,\n",
    "    'max': 6,\n",
    "    'palette': [\n",
    "        \"#1A5BAB\",  # Water\n",
    "        \"#358221\",  # Trees\n",
    "        \"#87D19E\",  # Flooded Vegetation\n",
    "        \"#FFDB5C\",  # Crops\n",
    "        \"#ED022A\",  # Built Area\n",
    "        \"#EDE9E4\",  # Bare ground\n",
    "        # \"#F2FAFF\",  # Snow/Ice\n",
    "        # \"#C8C8C8\",   # Clouds\n",
    "        # \"#C6AD8D\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map and add layer\n",
    "# Map = geemap.Map(center=[6.6, -1.7], zoom=10)\n",
    "# Set up the geemap Map\n",
    "Map = geemap.Map(center=location, zoom=12)\n",
    "Map.addLayer(clipped, {\n",
    "    'bands': ['B4', 'B3', 'B2'],  # RGB visualization\n",
    "    'min': 0,\n",
    "    'max': 0.3\n",
    "}, 'Clipped Sentinel-2 Image (Kumasi)')\n",
    "\n",
    "# Optionally add the ROI outline\n",
    "Map.addLayer(imageROI, {}, 'ROI Boundary')\n",
    "Map.addLayer(lulc_2017_remapped, esri_viz, \"ESRI Landcover\")\n",
    "Map.add_legend(title=\"ESRI Land Cover Legend\", labels=dict_legend[\"names\"], colors=dict_legend[\"colors\"])\n",
    "display(Map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f25e6f-f343-41ec-b454-3e77c54151bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_map.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae69b9-3ef8-4a76-b44c-4d5c2734c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define custom color codes\n",
    "custom_colors = [\n",
    "    \"#1A5BAB\",  # 0: Water\n",
    "    \"#358221\",  # 1: Trees\n",
    "    \"#87D19E\",  # 2: Flooded Vegetation\n",
    "    \"#FFDB5C\",  # 3: Crops\n",
    "    \"#ED022A\",  # 4: Built Area\n",
    "    \"#EDE9E4\",   # 5: Bare Ground\n",
    "    \"#F2FAFF\",  # Snow/Ice\n",
    "    \"#C8C8C8\",   # Clouds\n",
    "    \"#C6AD8D\"\n",
    "]\n",
    "\n",
    "# Create a colormap\n",
    "cmap = ListedColormap(custom_colors)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(predicted_map, cmap=cmap)\n",
    "plt.title(\"Predicted Land Cover Classes\")\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(ticks=range(len(custom_colors)))\n",
    "cbar.set_label('Class Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06964483-5a7d-4bf0-a078-1fb15d2b8064",
   "metadata": {},
   "source": [
    "#### Add extra bands to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3330432-ede7-445d-b27e-03126f406bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and add a single band (NDVI).\n",
    "ndvi = clipped.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "clipped = clipped.addBands(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0eeff-709f-4721-b2b0-268cac3d960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add landcover from esri as another band\n",
    "clipped = clipped.addBands(lulc_2017_remapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f5b3f-7a6d-498a-a756-3cdc05aece15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc_2017_remapped.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e30916-6343-4275-85e6-1ca335899967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "# Optional: Export\n",
    "geemap.ee_export_image(\n",
    "    clipped, filename='sentinel_obuasi_landcover_new.tif', scale=10, region=imageROI, file_per_band=False\n",
    ")\n",
    "\n",
    "print(\"Image prepared and clipped to Obuasi region!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e835f3-f181-4e6d-b096-94469d7a0e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_image = 'sentinel_obuasi_landcover_new.tif'\n",
    "# Read raster\n",
    "with rasterio.open(out_image) as src:\n",
    "    img = src.read()\n",
    "    transform = src.transform\n",
    "    width, height = src.width, src.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3738d-b5fc-4170-a915-dd9beafcbd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae564d58-55d9-4a2d-b428-8f2f8c5db2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bands = img[:5, :, :] # e.g., B2, B3, B4, B8, NDVI, Landcover\n",
    "labels = img[-1, :, :]\n",
    "normal_bands.shape[0]\n",
    "band_names = [\"B2\", \"B3\", \"B4\", \"B8\", \"NDVI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae616b7-8b29-4806-a00c-1f217604a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    1: \"Water\",\n",
    "    2: \"Trees\",\n",
    "    3: \"Flooded Vegetation\",\n",
    "    4: \"Crops\",\n",
    "    5: \"Built Area\",\n",
    "    6: \"Bare Ground\",\n",
    "    7: \"Snow Ice\",\n",
    "    8: \"Clouds\",\n",
    "    9: \"Rangeland\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75fdf9-2558-4dbe-b836-7cc3e2e6bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_bands(image_array, band_names):\n",
    "    \"\"\"Plots each individual band in grayscale.\"\"\"\n",
    "    num_bands = image_array.shape[0]\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    for i in range(num_bands):\n",
    "        plt.subplot(1, num_bands, i + 1)\n",
    "        band = image_array[i, :, :]  # Correctly select the (height, width) band\n",
    "        plt.imshow(band, cmap='gray')\n",
    "        plt.title(band_names[i])\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Individual Sentinel-2 Bands')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pixel_histograms(image_array, band_names):\n",
    "    \"\"\"Plots the histogram of pixel intensities for each band.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(image_array.shape[0]):\n",
    "        plt.hist(image_array[i, :, :].ravel(), bins=100, alpha=0.5, label=band_names[i])\n",
    "    plt.title(\"Pixel Value Distribution per Band\")\n",
    "    plt.xlabel(\"Pixel Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b64bd5-aa6f-4243-9150-a52b4f9e62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_bands(normal_bands, band_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f15eb0-24f3-49bb-aeed-e78de266d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_histograms(normal_bands, band_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2453b3-b848-41be-b4d6-0d4713b9720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801bd1b-9ad1-44b8-8f2f-4c9b5c2c864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(label_array, class_mapping):\n",
    "    \"\"\"Plots the class distribution based on pixel counts.\"\"\"\n",
    "    unique, counts = np.unique(label_array, return_counts=True)\n",
    "    # class_labels = [class_mapping.get(cls, f\"Class {cls}\") for cls in unique]\n",
    "\n",
    "    vectorized_map = np.vectorize(lambda cls: class_mapping.get(cls, f\"Class {cls}\"))\n",
    "    class_labels = vectorized_map(unique)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(class_labels, counts, color='skyblue')\n",
    "    plt.title(\"Land Cover Class Distribution\")\n",
    "    plt.xlabel(\"Land Cover Class\")\n",
    "    plt.ylabel(\"Pixel Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1897b-d1fe-4bdc-9896-a0445106f2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff66d0a-047a-49f9-b4f1-111510f365f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(labels, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353df91-253a-460f-bda4-fc2ac86799da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = pred +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f7478-bf8d-4966-8083-bc1db01b5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(pred_new, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a60c0-e6cf-4f40-8e5c-0f65cde7bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa03a1-4d93-48be-bf00-796e052a5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_band_correlation(image_array, band_names):\n",
    "    \"\"\"Plots a correlation matrix between bands.\"\"\"\n",
    "    reshaped = image_array.reshape(-1, image_array.shape[0])\n",
    "    df = pd.DataFrame(reshaped, columns=band_names)\n",
    "    corr = df.corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "    plt.title(\"Band Correlation Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232d445-a62b-4ab6-aad2-90372fb09964",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_band_correlation(normal_bands, band_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce454c17-49a0-4e6d-bc9a-af8710889eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e588a41-172d-4acc-914b-99ebce5de0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualisations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515ec66-1004-4e55-b5a8-a58d4618c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage (you can comment these out when integrating):\n",
    "# if __name__ == \"__main__\":\n",
    "#     normal_bands = img[:5, :, :] # e.g., B2, B3, B4, B8, NDVI, Landcover\n",
    "#     band_names = [\"B2\", \"B3\", \"B4\", \"B8\", \"NDVI\"]\n",
    "#     labels = img[:-1, :, :]\n",
    "#     class_mapping = {\n",
    "#         0: \"Water\",\n",
    "#         1: \"Trees\",\n",
    "#         2: \"Flooded Vegetation\",\n",
    "#         3: \"Crops\",\n",
    "#         4: \"Built Area\",\n",
    "#         5: \"Bare Ground\"\n",
    "#     }\n",
    "\n",
    "    plot_individual_bands(normal_bands, band_names)\n",
    "    # plot_pixel_histograms(normal_bands, band_names)\n",
    "    # plot_class_distribution(labels, class_mapping)\n",
    "    # plot_ndvi_histogram(normal_bands[:, :, -1])  # Assuming NDVI is last\n",
    "    # show_rgb(normal_bands, bands_indices=(2, 1, 0))\n",
    "    # plot_band_correlation(normal_bands, band_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73edee-ec34-4475-bae4-a7a6ea9542b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfa4ec-8304-4b1c-b3eb-00f8acc8a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_pixel_distribution_per_class(image_array, labels, class_mapping, band_names):\n",
    "    \"\"\"\n",
    "    Plots pixel value distributions per class for each band.\n",
    "\n",
    "    Args:\n",
    "        image_array (np.ndarray): Shape (H, W, B) raster image (bands last).\n",
    "        labels (np.ndarray): Shape (H, W) label mask (integer class IDs).\n",
    "        class_mapping (dict): Mapping {class_id: class_name}.\n",
    "        band_names (list): Names of the bands in the same order as image_array.\n",
    "    \"\"\"\n",
    "    num_bands = image_array.shape[0]\n",
    "    unique_classes = np.unique(labels)\n",
    "\n",
    "    plt.figure(figsize=(15, num_bands * 4))\n",
    "\n",
    "    for b in range(num_bands):\n",
    "        plt.subplot(num_bands, 1, b + 1)\n",
    "        for cls in unique_classes:\n",
    "            mask = labels == cls\n",
    "            if np.any(mask):\n",
    "                values = image_array[b, :, :][mask]\n",
    "                plt.hist(values, bins=50, alpha=0.5, label=class_mapping.get(cls, f\"Class {cls}\"), density=True)\n",
    "        \n",
    "        plt.title(f\"Pixel Value Distribution - {band_names[b]}\")\n",
    "        plt.xlabel(\"Pixel Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example inputs\n",
    "normal_bands = img[:5, :, :] # e.g., B2, B3, B4, B8, NDVI, Landcover\n",
    "band_names = [\"B2\", \"B3\", \"B4\", \"B8\", \"NDVI\"]\n",
    "labels = img[-1, :, :]\n",
    "class_mapping = {\n",
    "    1: \"Water\",\n",
    "    2: \"Trees\",\n",
    "    3: \"Flooded Vegetation\",\n",
    "    4: \"Crops\",\n",
    "    5: \"Built Area\",\n",
    "    6: \"Bare Ground\",\n",
    "    7: \"Snow Ice\",\n",
    "    8: \"Clouds\",\n",
    "    9: \"Rangeland\"\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653520c-9700-492e-8376-3e4d0bc12911",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21408c-7208-4c2d-9f5f-c73f56c41449",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_distribution_per_class(normal_bands, labels, class_mapping, band_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3063e2",
   "metadata": {},
   "source": [
    "## Graph Representation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e528a6",
   "metadata": {},
   "source": [
    "### Approach 1: Using Grid based Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5332a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4059b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c587a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0335ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape bands\n",
    "bands_data = np.moveaxis(img, 0, -1)  # (height, width, bands)\n",
    "# Flatten spatial dimensions\n",
    "features = bands_data.reshape(-1, bands_data.shape[2])  # (nodes, features)\n",
    "\n",
    "# Normalize\n",
    "features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-8)\n",
    "features = torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ff337",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3eaa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build adjacency (4-neighbors)\n",
    "G = nx.grid_2d_graph(height, width)  # simple 4-connectivity\n",
    "mapping = {(i, j): i * width + j for i in range(height) for j in range(width)}\n",
    "G = nx.relabel_nodes(G, mapping)\n",
    "edges = list(G.edges)\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy labels (real case: use manually annotated labels or classify unsupervised clusters)\n",
    "num_classes = 9\n",
    "labels = torch.randint(0, num_classes, (features.shape[0],), dtype=torch.long)\n",
    "\n",
    "# PyG Data\n",
    "data = Data(x=features, edge_index=edge_index, y=labels)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aff53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0540f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from rasterio.warp import transform_bounds\n",
    "from pyproj import CRS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_grid_from_raster(raster_path, cell_size=30, grid_crs='EPSG:32630', to_wgs84=True):\n",
    "    # Step 1: Open the raster and get bounds\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        original_crs = src.crs\n",
    "        bounds = src.bounds\n",
    "\n",
    "        print(f\"[INFO] Original CRS: {original_crs}\")\n",
    "        \n",
    "        # Step 2: Reproject bounds to grid_crs (e.g., UTM)\n",
    "        bounds_projected = transform_bounds(original_crs, grid_crs, *bounds)\n",
    "\n",
    "    # Step 3: Create grid using projected coordinates\n",
    "    minx, miny, maxx, maxy = bounds_projected\n",
    "    cols = int((maxx - minx) // cell_size)\n",
    "    rows = int((maxy - miny) // cell_size)\n",
    "\n",
    "    print(f\"[INFO] Grid dimensions: {rows} rows x {cols} cols\")\n",
    "\n",
    "    grid_polygons = []\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            x1 = minx + col * cell_size\n",
    "            y1 = miny + row * cell_size\n",
    "            x2 = x1 + cell_size\n",
    "            y2 = y1 + cell_size\n",
    "            grid_polygons.append(box(x1, y1, x2, y2))\n",
    "\n",
    "    grid_gdf = gpd.GeoDataFrame({'geometry': grid_polygons}, crs=grid_crs)\n",
    "\n",
    "    # Step 4: Optionally reproject back to WGS84 for visualization/export\n",
    "    if to_wgs84:\n",
    "        grid_gdf = grid_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    return grid_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geotif_location = 'sentinel2_kumasi.tif'\n",
    "grid_gdf = generate_grid_from_raster(geotif_location, cell_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7d57a",
   "metadata": {},
   "source": [
    "### Adding the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterstats --quietz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "\n",
    "stats = zonal_stats(grid_gdf, \"esri_landcover_kumasi_label.tif\", stats=['majority'], categorical=True)\n",
    "grid_gdf['label'] = [s.get('majority', -1) for s in stats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize\n",
    "grid_gdf.plot(edgecolor='gray', facecolor='none', linewidth=0.2)\n",
    "plt.title(\"Generated Grid (WGS84)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fdb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a6b89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed5d2e43-de7e-4f2b-824c-45208c57b180",
   "metadata": {},
   "source": [
    "### Save and export grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f517d-a531-45c0-b63d-3cddcd1b9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fc = ee.FeatureCollection('projects/nigtroy/assets/grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc308d3-dd6c-40a1-b7f3-86fa7dfdb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=location, zoom=12)\n",
    "Map.addLayer(clipped, {\n",
    "    'bands': ['B4', 'B3', 'B2'],  # RGB visualization\n",
    "    'min': 0,\n",
    "    'max': 0.3\n",
    "}, 'Clipped Sentinel-2 Image (Kumasi)')\n",
    "\n",
    "# Optionally add the ROI outline\n",
    "Map.addLayer(imageROI, {}, 'ROI Boundary')\n",
    "# Add Grid Overlay\n",
    "Map.addLayer(grid_fc, {}, \"Grid\")\n",
    "Map.addLayer(lulc_2017_remapped, esri_viz, \"ESRI Landcover\")\n",
    "Map.add_legend(title=\"ESRI Land Cover Legend\", labels=dict_legend[\"names\"], colors=dict_legend[\"colors\"])\n",
    "display(Map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24896ad0-2364-489e-9981-7992a5525fc4",
   "metadata": {},
   "source": [
    "### Extracting Labels per Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f9a9d-43fb-4874-be16-a0a5120ced7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label to each grid cell using mode (most common pixel)\n",
    "labeled_grid = lulc_2017_remapped.reduceRegions(\n",
    "    collection=grid_fc,\n",
    "    reducer=ee.Reducer.mode(),  # Or .first() if single pixel coverage\n",
    "    scale=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963f21d-cccf-40a8-847d-2bca002c36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=labeled_grid,\n",
    "    description='Grid_with_LULC_labels',\n",
    "    folder='EarthEngineExports',\n",
    "    fileNamePrefix='grid_labeled',\n",
    "    fileFormat='GeoJSON'\n",
    ")\n",
    "task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa29529-b88d-4123-a808-3ce798dc9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled grid\n",
    "gdf = gpd.read_file('grid_labeled.geojson')\n",
    "\n",
    "# Optional: drop geometries with missing labels (-1 or NaN)\n",
    "gdf = gdf[gdf['label'] >= 0].reset_index(drop=True)\n",
    "\n",
    "# Encode categorical label (if not already int)\n",
    "labels = torch.tensor(gdf['label'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a1813-ed0a-4026-a840-8414aac19aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use centroids as node features (or any other features you want)\n",
    "centroids = gdf.geometry.centroid\n",
    "features = torch.tensor(\n",
    "    [[pt.x, pt.y] for pt in centroids],\n",
    "    dtype=torch.float\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6852f3b-4ec3-44a7-bd56-6720e61ede3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph using Queen contiguity (shared edges or corners)\n",
    "def get_adjacency(gdf):\n",
    "    graph = nx.Graph()\n",
    "    for idx, geom in gdf.geometry.items():\n",
    "        graph.add_node(idx)\n",
    "    for i in range(len(gdf)):\n",
    "        for j in range(i + 1, len(gdf)):\n",
    "            if gdf.geometry[i].touches(gdf.geometry[j]):\n",
    "                graph.add_edge(i, j)\n",
    "    return graph\n",
    "\n",
    "G = get_adjacency(gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19818e3a-2754-4301-8ba0-fcef892cbf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Since edges are undirected, add reverse direction too\n",
    "edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "# Create the PyTorch Geometric graph object\n",
    "data = Data(x=features, edge_index=edge_index, y=labels)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acb600-62d9-4165-8309-247b234c7c88",
   "metadata": {},
   "source": [
    "### Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d287c0-8bc2-4668-84c1-99a309668506",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_path  = 'sentinel_obuasi_landcover_new.tif'\n",
    "# Read raster\n",
    "with rasterio.open(raster_path) as src:\n",
    "    img = src.read()  # (bands, height, width)\n",
    "    transform = src.transform\n",
    "    height, width = src.height, src.width\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eab31d-db9a-4faa-a13c-b92a4934c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentinel_image(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        img = src.read()  # shape: (bands, height, width)\n",
    "        meta = src.meta\n",
    "        band_names = ['B2', 'B3', 'B4', 'B8', 'NDVI', 'land_cover']\n",
    "    return img, meta, band_names\n",
    "\n",
    "def summarize_bands(img, band_names):\n",
    "    summary = []\n",
    "    for i in range(img.shape[0]):\n",
    "        band = img[i]\n",
    "        print(i)\n",
    "        summary.append({\n",
    "            'Band': band_names[i],\n",
    "            'Min': float(np.nanmin(band)),\n",
    "            'Max': float(np.nanmax(band)),\n",
    "            'Mean': float(np.nanmean(band)),\n",
    "            'Std': float(np.nanstd(band))\n",
    "        })\n",
    "    return pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03348cee-8124-4041-843d-51d99e298fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b139ae-ca2d-4dd2-aa2d-26c57256e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, meta, bands = read_sentinel_image('sentinel_obuasi_landcover_new.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280ad87-bd21-424d-b55e-f81794461700",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_bands(img, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74184154-fc59-4359-a0be-c2b6e0e47255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate bands: features = first 5 bands, labels = 6th band\n",
    "features_raw = img[:5, :, :]  # shape: (5, H, W)\n",
    "labels_raw = img[5, :, :]     # shape: (H, W)\n",
    "\n",
    "# Move channel to last axis\n",
    "bands_data = np.moveaxis(features_raw, 0, -1)  # shape: (H, W, 5)\n",
    "\n",
    "# Flatten spatial dimensions\n",
    "features = bands_data.reshape(-1, bands_data.shape[2])  # shape: (H*W, 5)\n",
    "labels = labels_raw.flatten()                           # shape: (H*W,)\n",
    "\n",
    "# Mask invalid labels (e.g., 0 or nodata values, depending on your LULC encoding)\n",
    "valid_mask = labels > 0  # assuming 0 is invalid\n",
    "\n",
    "# Normalize features (only valid pixels)\n",
    "features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-8)\n",
    "features = torch.tensor(features[valid_mask], dtype=torch.float)\n",
    "\n",
    "# Labels\n",
    "labels = torch.tensor(labels[valid_mask] - 1, dtype=torch.long)  # subtract 1 if labels are 1-indexed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2466f-c176-4408-bfff-3e8fb484f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a5afb-77e1-426b-90a5-5f93028a87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.bincount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c3d27-8ed1-4aac-aa37-334c4aeb1b3e",
   "metadata": {},
   "source": [
    "In order for some classes to not end up being ignored due to the class imbalance, it is important to upsample the class values such that the model can see them during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b213722-8d92-40a8-823a-657e3a570b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "# Build adjacency (4-neighbors)\n",
    "G = nx.grid_2d_graph(height, width)\n",
    "mapping = {(i, j): i * width + j for i in range(height) for j in range(width)}\n",
    "G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "# Filter edges for valid nodes only\n",
    "valid_indices = np.where(valid_mask)[0]\n",
    "valid_set = set(valid_indices)\n",
    "edges = [(u, v) for u, v in G.edges() if u in valid_set and v in valid_set]\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# PyG Data\n",
    "original_data = Data(x=features, edge_index=edge_index, y=labels)\n",
    "\n",
    "print(original_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbbf59-89d8-4415-b96e-d555e043b007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62adf28-c67b-4ab5-971a-7e6a4dc72ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175ed89-5951-4e8e-9fb9-739e770ed1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1766f634-1ac0-44b1-ab94-955a10629445",
   "metadata": {},
   "source": [
    "## Upsampling training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eac50c-ce3b-411e-b91c-3c691bf12bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def upsample_classes(features, labels, min_samples=10000):\n",
    "    unique_classes = torch.unique(labels)\n",
    "    upsampled_features = []\n",
    "    upsampled_labels = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        cls_mask = (labels == cls)\n",
    "        cls_feats = features[cls_mask]\n",
    "        cls_labs = labels[cls_mask]\n",
    "\n",
    "        if len(cls_feats) < min_samples:\n",
    "            repeat_factor = int(np.ceil(min_samples / len(cls_feats)))\n",
    "            cls_feats = cls_feats.repeat((repeat_factor, 1))[:min_samples]\n",
    "            cls_labs = cls_labs.repeat(repeat_factor)[:min_samples]\n",
    "\n",
    "        upsampled_features.append(cls_feats)\n",
    "        upsampled_labels.append(cls_labs)\n",
    "\n",
    "    X_bal = torch.cat(upsampled_features, dim=0)\n",
    "    Y_bal = torch.cat(upsampled_labels, dim=0)\n",
    "\n",
    "    perm = torch.randperm(X_bal.size(0))\n",
    "    return X_bal[perm], Y_bal[perm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b2b70-7a0f-4f3f-ab0e-9969ccde1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Stratified split (on raw data)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, test_idx in sss.split(original_data.x, original_data.y):\n",
    "    train_x = original_data.x[train_idx]\n",
    "    train_y = original_data.y[train_idx]\n",
    "    test_x = original_data.x[test_idx]\n",
    "    test_y = original_data.y[test_idx]\n",
    "\n",
    "# Step 2: Upsample training data only\n",
    "X_train_bal, Y_train_bal = upsample_classes(train_x, train_y, min_samples=50000)\n",
    "\n",
    "# Step 3: Build PyG Data using upsampled training set and real test set\n",
    "train_mask = torch.ones(len(X_train_bal), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(X_train_bal) + len(test_y), dtype=torch.bool)\n",
    "test_mask[len(X_train_bal):] = True\n",
    "\n",
    "# Concatenate train + test for unified graph structure\n",
    "X_all = torch.cat([X_train_bal, test_x], dim=0)\n",
    "Y_all = torch.cat([Y_train_bal, test_y], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6930681-81f0-4d11-8536-559ce8ca7f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new train and test masks\n",
    "train_mask = torch.zeros(len(X_all), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(X_all), dtype=torch.bool)\n",
    "train_mask[:len(X_train_bal)] = True\n",
    "test_mask[len(X_train_bal):] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cf43a-40d9-4ae9-b4a4-82a0d8c2ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361c6c1-e768-4a54-81d5-79bf35e253d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7abf20-e4b8-4baa-a3a6-be8f835c4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f7b2b-67c7-4b1e-81e1-cab1278bca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_bal.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1f0f1-5e7e-42b9-9431-330c67c96845",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_bal.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b9614-ec1a-4b0e-878d-a25d388c9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c5da7-920b-4378-acc0-3d6e61f5b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fe254-900f-4cb2-ba98-ec87f99d21df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d4084-ca6d-4d8a-aaca-e75b2f3340dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.empty((2, 0), dtype=torch.long)  # no edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195d145-c70c-4809-b8c5-4f2386f7cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "new_data = Data(\n",
    "    x=X_all,\n",
    "    y=Y_all,\n",
    "    edge_index=edge_index,  # use empty or real adjacency\n",
    "    train_mask=train_mask,\n",
    "    test_mask=test_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a592528-cae7-4723-8892-85023c8b5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c841bd9-321d-47c5-9c1e-4ca7b3cb5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de7579-9397-4cb0-8925-26bb4cf15590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import train_test_split_edges\n",
    "# data = original_data\n",
    "# num_nodes = data.num_nodes\n",
    "# perm = torch.randperm(num_nodes)\n",
    "# train_idx = perm[:int(0.8 * num_nodes)]\n",
    "# test_idx = perm[int(0.8 * num_nodes):]\n",
    "\n",
    "# data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "# data.train_mask[train_idx] = True\n",
    "# data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "# data.test_mask[test_idx] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d47f5c-7558-43e3-8213-050a7dc9a398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ee46b-819a-4280-b7ba-57b47c1dbff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe9383-3314-44b0-85f1-04a29508d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GCN(input_dim=data.num_node_features, hidden_dim=32, num_classes=data.y.max().item() + 1).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881c9e2-fff0-4770-9c6c-768ad9f8dff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb47c7-0b4f-4171-b12f-95adb768e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21ec0a-d7aa-4fab-8257-ed09d56b1154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1abd05-7dad-4af0-92cb-a7da57b512bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "import time \n",
    "start = time.time()\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f'Model trained for about {end - start} seconds for {epoch} epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13719748-55f0-4305-bbd4-ccc35f9d2758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd38a7d-5031-48ba-81b5-5f6f6d8251fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(original_data.x, original_data.edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f3790-2993-4134-b979-944c7368f8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830e7d4-f0b4-4c5a-83c3-1397918ac162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values and their counts\n",
    "unique, counts = np.unique(pred, return_counts=True)\n",
    "\n",
    "# Combine into a dictionary (optional)\n",
    "counts_dict = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Unique values:\", unique)\n",
    "print(\"Counts:\", counts)\n",
    "print(\"As dictionary:\", counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601e80e-5907-46b2-b17e-0a66cbafbf63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6563d3-b6f4-4e9c-a176-bfcafe501dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fefed3-731e-400d-b0e5-8bcc8b7acc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNRes(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(GCNRes, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim) # Added a layer\n",
    "        self.conv3 = GCNConv(hidden_dim, num_classes) # Final layer\n",
    "\n",
    "        # Optional: Linear layer for residual connection if input_dim != hidden_dim\n",
    "        self.lin_skip = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else None\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training) # Dropout after activation\n",
    "\n",
    "        # Second layer (example of simple residual connection)\n",
    "        identity = x\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Residual connection\n",
    "        # If input_dim != hidden_dim, need to project identity\n",
    "        # Here assuming identity (output of conv1) has same dim as input to conv2\n",
    "        x = x + identity # Add residual connection\n",
    "\n",
    "        # Final layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# How it would integrate:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCNRes(input_dim=data.num_node_features, hidden_dim=64, num_classes=data.y.max().item() + 1).to(device)\n",
    "# (Rest of training loop remains similar)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f1bf8-2131-4281-8f2d-f8be5dd75342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "import time \n",
    "start = time.time()\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f'Model trained for about {end - start} seconds for {epoch} epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111734f0-9064-4b2c-8cde-2925b9b19385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(original_data.x, original_data.edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1fff4-3c18-4114-b86b-621d53d4a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values and their counts\n",
    "unique, counts = np.unique(pred, return_counts=True)\n",
    "\n",
    "# Combine into a dictionary (optional)\n",
    "counts_dict = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Unique values:\", unique)\n",
    "print(\"Counts:\", counts)\n",
    "print(\"As dictionary:\", counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526843e-fd30-430d-8a4b-880e3a669871",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829c01f-8254-44cc-9444-59eb5ea82231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a2f59-d42e-4602-84b2-a2a1454a4c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
